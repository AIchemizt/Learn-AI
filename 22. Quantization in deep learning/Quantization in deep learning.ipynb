{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(3)\n",
    "from tensorflow import keras\n",
    "from keras.datasets import mnist\n",
    "from tensorflow.math import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the MNIST data from keras.datasets\n",
    "\n",
    "(X_train, Y_train), (X_test, Y_test) =  mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28) (60000,) (10000, 28, 28) (10000,)\n"
     ]
    }
   ],
   "source": [
    "# shape of the numpy arrays\n",
    "print(X_train.shape, Y_train.shape, X_test.shape, Y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training Images = 60,000\n",
    "\n",
    "Image dimension --> 28 x 28\n",
    "\n",
    "Grayscale Image --> 1 channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   1  26 111 195 230\n",
      "   30   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0  28 107 195 254 254 254 244\n",
      "   20   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0  46 167 248 254 222 146 150 254 174\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0  65 223 246 254 153  61  10   0  48 254 129\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0  85 175 164  80   2   0   0   0  48 254 120\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 182 254  16\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 207 254  16\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 207 202   3\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  28 248 170   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0 107 254  61   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0 166 252  30   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0 191 206   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0 191 206   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0  14 246 186   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0  91 254  77   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0 175 254  48   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0 175 240  27   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0 215 222   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0 115 255 152   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0 134 255  68   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]]\n"
     ]
    }
   ],
   "source": [
    "print(X_train[42])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 28)\n"
     ]
    }
   ],
   "source": [
    "print(X_train[42].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    }
   ],
   "source": [
    "plt.imshow(X_train[42])\n",
    "plt.show()\n",
    "\n",
    "# print the corresponding label\n",
    "print(Y_train[42])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4 5 6 7 8 9]\n",
      "[0 1 2 3 4 5 6 7 8 9]\n"
     ]
    }
   ],
   "source": [
    "# unique values in Y_train\n",
    "print(np.unique(Y_train))\n",
    "\n",
    "# unique values in Y_test\n",
    "print(np.unique(Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaling the values\n",
    "\n",
    "X_train = X_train/255\n",
    "X_test = X_test/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.00392157 0.10196078 0.43529412 0.76470588 0.90196078\n",
      "  0.11764706 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.10980392\n",
      "  0.41960784 0.76470588 0.99607843 0.99607843 0.99607843 0.95686275\n",
      "  0.07843137 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.18039216 0.65490196 0.97254902\n",
      "  0.99607843 0.87058824 0.57254902 0.58823529 0.99607843 0.68235294\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.25490196 0.8745098  0.96470588 0.99607843 0.6\n",
      "  0.23921569 0.03921569 0.         0.18823529 0.99607843 0.50588235\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.33333333 0.68627451 0.64313725 0.31372549 0.00784314\n",
      "  0.         0.         0.         0.18823529 0.99607843 0.47058824\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.71372549 0.99607843 0.0627451\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.81176471 0.99607843 0.0627451\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.81176471 0.79215686 0.01176471\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.10980392 0.97254902 0.66666667 0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.41960784 0.99607843 0.23921569 0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.65098039 0.98823529 0.11764706 0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.74901961 0.80784314 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.74901961 0.80784314 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.05490196 0.96470588 0.72941176 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.35686275 0.99607843 0.30196078 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.68627451 0.99607843 0.18823529 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.68627451 0.94117647 0.10588235 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.84313725 0.87058824 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.45098039 1.         0.59607843 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.5254902  1.         0.26666667 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "print(X_train[42])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-31 01:38:46.870770: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M2\n",
      "2024-05-31 01:38:46.870798: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 8.00 GB\n",
      "2024-05-31 01:38:46.870813: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 2.67 GB\n",
      "2024-05-31 01:38:46.871235: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:303] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-05-31 01:38:46.871605: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:269] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "# setting up the layers of the Neural  Network\n",
    "\n",
    "model = keras.Sequential([\n",
    "                          keras.layers.Flatten(input_shape=(28,28)),\n",
    "                          keras.layers.Dense(50, activation='relu'),\n",
    "                          keras.layers.Dense(10, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compiling the Neural Network\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss = 'sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-31 01:39:23.531551: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1875/1875 [==============================] - 10s 4ms/step - loss: 0.3853 - accuracy: 0.8911\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2969 - accuracy: 0.9172\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2907 - accuracy: 0.9191\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2895 - accuracy: 0.9197\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2921 - accuracy: 0.9197\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2936 - accuracy: 0.9189\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2968 - accuracy: 0.9190\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2994 - accuracy: 0.9183\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.3022 - accuracy: 0.9188\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.3066 - accuracy: 0.9181\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x17ffc8520>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# training the Neural Network\n",
    "\n",
    "model.fit(X_train, Y_train, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 29/313 [=>............................] - ETA: 1s - loss: 0.3444 - accuracy: 0.9030"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-31 01:40:58.559780: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 4ms/step - loss: 0.3334 - accuracy: 0.9144\n"
     ]
    }
   ],
   "source": [
    "# Accuracy on Test data\n",
    "\n",
    "loss, accuracy = model.evaluate(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./saved_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./saved_model/assets\n"
     ]
    }
   ],
   "source": [
    "# Save the trained model to a directory\n",
    "model.save(\"./saved_model/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1) Post training quantization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Without quantization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-31 01:53:45.298388: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:364] Ignored output_format.\n",
      "2024-05-31 01:53:45.298405: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:367] Ignored drop_control_dependency.\n",
      "2024-05-31 01:53:45.298562: I tensorflow/cc/saved_model/reader.cc:45] Reading SavedModel from: ./saved_model\n",
      "2024-05-31 01:53:45.299314: I tensorflow/cc/saved_model/reader.cc:91] Reading meta graph with tags { serve }\n",
      "2024-05-31 01:53:45.299321: I tensorflow/cc/saved_model/reader.cc:132] Reading SavedModel debug info (if present) from: ./saved_model\n",
      "2024-05-31 01:53:45.301187: I tensorflow/cc/saved_model/loader.cc:231] Restoring SavedModel bundle.\n",
      "2024-05-31 01:53:45.334631: I tensorflow/cc/saved_model/loader.cc:215] Running initialization op on SavedModel bundle at path: ./saved_model\n",
      "2024-05-31 01:53:45.344538: I tensorflow/cc/saved_model/loader.cc:314] SavedModel load for tags { serve }; Status: success: OK. Took 45977 microseconds.\n"
     ]
    }
   ],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_saved_model(\"./saved_model\")\n",
    "tflite_model=converter.convert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "161004"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tflite_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**With quantization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-31 02:02:12.170430: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:364] Ignored output_format.\n",
      "2024-05-31 02:02:12.170447: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:367] Ignored drop_control_dependency.\n",
      "2024-05-31 02:02:12.170653: I tensorflow/cc/saved_model/reader.cc:45] Reading SavedModel from: ./saved_model\n",
      "2024-05-31 02:02:12.171374: I tensorflow/cc/saved_model/reader.cc:91] Reading meta graph with tags { serve }\n",
      "2024-05-31 02:02:12.171381: I tensorflow/cc/saved_model/reader.cc:132] Reading SavedModel debug info (if present) from: ./saved_model\n",
      "2024-05-31 02:02:12.173431: I tensorflow/cc/saved_model/loader.cc:231] Restoring SavedModel bundle.\n",
      "2024-05-31 02:02:12.207782: I tensorflow/cc/saved_model/loader.cc:215] Running initialization op on SavedModel bundle at path: ./saved_model\n",
      "2024-05-31 02:02:12.217503: I tensorflow/cc/saved_model/loader.cc:314] SavedModel load for tags { serve }; Status: success: OK. Took 46850 microseconds.\n"
     ]
    }
   ],
   "source": [
    "converter=tf.lite.TFLiteConverter.from_saved_model(\"./saved_model\")\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "tflite_quant_model = converter.convert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43480"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tflite_quant_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the TFLite models to files\n",
    "with open(\"tflite_model.tflite\",\"wb\") as f:\n",
    "    f.write(tflite_model)\n",
    "\n",
    "with open(\"tflite_quant_model.tflite\",\"wb\") as f:\n",
    "    f.write(tflite_quant_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2) Quantization aware training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " quantize_layer (QuantizeLa  (None, 28, 28)            3         \n",
      " yer)                                                            \n",
      "                                                                 \n",
      " quant_flatten (QuantizeWra  (None, 784)               1         \n",
      " pperV2)                                                         \n",
      "                                                                 \n",
      " quant_dense (QuantizeWrapp  (None, 50)                39255     \n",
      " erV2)                                                           \n",
      "                                                                 \n",
      " quant_dense_1 (QuantizeWra  (None, 10)                515       \n",
      " pperV2)                                                         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 39774 (155.37 KB)\n",
      "Trainable params: 39760 (155.31 KB)\n",
      "Non-trainable params: 14 (56.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Quantize the entire model using Quantization Aware Training (QAT)\n",
    "import tensorflow_model_optimization as tfmot\n",
    "\n",
    "quantize_model = tfmot.quantization.keras.quantize_model\n",
    "\n",
    "q_aware_model = quantize_model(model)\n",
    "\n",
    "# Compile the quantization aware model\n",
    "q_aware_model.compile(optimizer=\"adam\",\n",
    "                      loss=\"sparse_categorical_crossentropy\",\n",
    "                      metrics=[\"accuracy\"])\n",
    "\n",
    "# Print the model summary to see the architecture\n",
    "q_aware_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-31 02:16:25.062828: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1875/1875 [==============================] - 19s 9ms/step - loss: 0.4632 - accuracy: 0.8702\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x10ab84100>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the quantization aware model for 1 epoch\n",
    "q_aware_model.fit(X_train,Y_train,epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  9/313 [..............................] - ETA: 1s - loss: 0.2508 - accuracy: 0.9410 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-31 02:16:54.946915: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 2s 5ms/step - loss: 0.3649 - accuracy: 0.9093\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3648834824562073, 0.9093000292778015]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the quantization aware model on the test data\n",
    "q_aware_model.evaluate(X_test,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/tmp2zzlwtgf/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/tmp2zzlwtgf/assets\n",
      "/Users/abhishek/tensorflow-test/env/lib/python3.8/site-packages/tensorflow/lite/python/convert.py:887: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
      "  warnings.warn(\n",
      "2024-05-31 02:19:26.487748: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:364] Ignored output_format.\n",
      "2024-05-31 02:19:26.487762: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:367] Ignored drop_control_dependency.\n",
      "2024-05-31 02:19:26.487917: I tensorflow/cc/saved_model/reader.cc:45] Reading SavedModel from: /var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/tmp2zzlwtgf\n",
      "2024-05-31 02:19:26.489453: I tensorflow/cc/saved_model/reader.cc:91] Reading meta graph with tags { serve }\n",
      "2024-05-31 02:19:26.489460: I tensorflow/cc/saved_model/reader.cc:132] Reading SavedModel debug info (if present) from: /var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/tmp2zzlwtgf\n",
      "2024-05-31 02:19:26.494758: I tensorflow/cc/saved_model/loader.cc:231] Restoring SavedModel bundle.\n",
      "2024-05-31 02:19:26.546581: I tensorflow/cc/saved_model/loader.cc:215] Running initialization op on SavedModel bundle at path: /var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/tmp2zzlwtgf\n",
      "2024-05-31 02:19:26.562467: I tensorflow/cc/saved_model/loader.cc:314] SavedModel load for tags { serve }; Status: success: OK. Took 74550 microseconds.\n"
     ]
    }
   ],
   "source": [
    "# Convert the quantization aware trained model to TFLite format\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(q_aware_model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "tflite_qaware_model = converter.convert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the quantization aware trained TFLite model to a file\n",
    "with open(\"tflite_qaware_model.tflite\",\"wb\") as f:\n",
    "    f.write(tflite_qaware_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
