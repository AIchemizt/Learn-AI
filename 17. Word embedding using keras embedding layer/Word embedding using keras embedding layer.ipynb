{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing essential libraries\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.text import one_hot\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our small dataset of reviews\n",
    "\n",
    "# Defining a list of reviews\n",
    "reviews = ['nice food',\n",
    "        'amazing restaurant',\n",
    "        'too good',\n",
    "        'just loved it!',\n",
    "        'will go again',\n",
    "        'horrible food',\n",
    "        'never go there',\n",
    "        'poor service',\n",
    "        'poor quality',\n",
    "        'needs improvement']\n",
    "\n",
    "# Creating an array for sentiments\n",
    "sentiment = np.array([1,1,1,1,1,0,0,0,0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[6, 28]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# one_hot encoding example\n",
    "# it take 2 value first is word & second is range\n",
    "\n",
    "one_hot(\"amazing restaurant\",30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[14, 2],\n",
       " [6, 28],\n",
       " [7, 16],\n",
       " [10, 19, 7],\n",
       " [14, 24, 14],\n",
       " [12, 2],\n",
       " [14, 24, 26],\n",
       " [14, 2],\n",
       " [14, 15],\n",
       " [13, 19]]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " # Defining the size of the vocabulary\n",
    "\n",
    "vocab_size = 30\n",
    "\n",
    "# Encoding reviews using one_hot, List comprehension\n",
    "encoded_reviews = [one_hot(d,vocab_size) for d in reviews]\n",
    "encoded_reviews\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[14,  2,  0],\n",
       "       [ 6, 28,  0],\n",
       "       [ 7, 16,  0],\n",
       "       [10, 19,  7],\n",
       "       [14, 24, 14],\n",
       "       [12,  2,  0],\n",
       "       [14, 24, 26],\n",
       "       [14,  2,  0],\n",
       "       [14, 15,  0],\n",
       "       [13, 19,  0]], dtype=int32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Defining the maximum length of padded sequences\n",
    "max_length = 3\n",
    "\n",
    "# Padding sequences\n",
    "padded_reviews = pad_sequences(encoded_reviews,maxlen=max_length,padding=\"post\")\n",
    "padded_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the size of the embedding vectors\n",
    "Embeded_vector_size = 4\n",
    "\n",
    "# Creating a Sequential model\n",
    "model = Sequential()\n",
    "\n",
    "# Adding Embedding layer\n",
    "model.add(Embedding(input_dim=vocab_size, output_dim=Embeded_vector_size, input_length=max_length, name=\"embedding\"))\n",
    "\n",
    "\n",
    "# Adding Flatten layer to flatten the input\n",
    "model.add(Flatten())\n",
    "\n",
    "# Adding Dense layer with sigmoid activation.\n",
    "model.add(Dense(1,activation=\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=padded_reviews\n",
    "y=sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 3, 4)              120       \n",
      "                                                                 \n",
      " flatten_5 (Flatten)         (None, 12)                0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 13        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 133 (532.00 Byte)\n",
      "Trainable params: 133 (532.00 Byte)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Compiling the model\n",
    "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x15cef29a0>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the model.\n",
    "model.fit(x, y, epochs=50, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 23ms/step - loss: 0.5863 - accuracy: 0.9000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8999999761581421"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss,accuracy=model.evaluate(x,y)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.07128103, -0.1380862 , -0.08433288,  0.13980511],\n",
       "       [ 0.04097874, -0.01196454, -0.02463349, -0.03068678],\n",
       "       [ 0.1192823 , -0.04936989, -0.13902679,  0.12226249],\n",
       "       [ 0.03737742,  0.04596836, -0.04306164, -0.03496295],\n",
       "       [ 0.01129245, -0.02024971, -0.02897176, -0.03455574],\n",
       "       [-0.01391552,  0.02276974, -0.03563224,  0.0126181 ],\n",
       "       [-0.13200042,  0.10503878,  0.13546695,  0.14926015],\n",
       "       [-0.04189454,  0.15295918,  0.13960473,  0.12077454],\n",
       "       [-0.0150594 , -0.04674103, -0.01743301, -0.04402265],\n",
       "       [ 0.04417099, -0.0344281 ,  0.0137894 , -0.04747739],\n",
       "       [-0.13429049,  0.12932944,  0.0977078 ,  0.09436398],\n",
       "       [-0.00100295, -0.00375133,  0.03894799, -0.03270918],\n",
       "       [ 0.13431968, -0.1612863 , -0.10660245, -0.07168186],\n",
       "       [ 0.06178768, -0.13740589, -0.08239155, -0.09079581],\n",
       "       [ 0.13109568,  0.16781166, -0.05286231, -0.10544907],\n",
       "       [ 0.09308697, -0.1122665 , -0.12299113,  0.10237128],\n",
       "       [-0.10193539,  0.07904477,  0.07359082, -0.0591313 ],\n",
       "       [ 0.04364803,  0.04536383, -0.04786104, -0.02312763],\n",
       "       [ 0.00181871,  0.01552716,  0.01225183,  0.04145907],\n",
       "       [ 0.00985809, -0.03081914, -0.03424995,  0.06473224],\n",
       "       [ 0.04163119, -0.00786694, -0.00797876, -0.03502548],\n",
       "       [ 0.02958603, -0.03857942,  0.0470384 , -0.01168883],\n",
       "       [ 0.04440334, -0.01363022, -0.00497941,  0.03017801],\n",
       "       [-0.00647401, -0.04924997, -0.0069886 , -0.02606525],\n",
       "       [-0.02661897,  0.03635935,  0.00142242,  0.02443852],\n",
       "       [ 0.01878103, -0.02156625, -0.00261939, -0.02834575],\n",
       "       [-0.12908575, -0.14837702, -0.14328946,  0.08353525],\n",
       "       [-0.04162432, -0.04996729,  0.01302341,  0.00996244],\n",
       "       [-0.08874618,  0.08030467,  0.12035143, -0.09427041],\n",
       "       [-0.03005934,  0.01912307,  0.04469255,  0.01929014]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting the weights of the Embedding layer\n",
    "\n",
    "weights=model.get_layer(\"embedding\").get_weights()[0]\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Checking for first word, \"nice food\" whose one_hot encoding is (14,2)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.13109568,  0.16781166, -0.05286231, -0.10544907], dtype=float32)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Displaying the weights at index 14\n",
    "weights[14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.1192823 , -0.04936989, -0.13902679,  0.12226249], dtype=float32)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Displaying the weights at index 2\n",
    "weights[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**So above array the vector for first word nice food, now they are not very similar becoz our dataset was very small, but this how they Implemented**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow-test",
   "language": "python",
   "name": "tensorflow-test"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
