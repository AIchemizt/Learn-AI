{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sigmoid Activation Function:**\n",
    "\n",
    "The sigmoid is a mathematical function that maps input values to a value between 0 and 1, making it useful for binary classification and logistic regression problems. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\sigma(x) = \\frac{1}{1 + e^{-x}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9820137900379085\n"
     ]
    }
   ],
   "source": [
    "def sigmoid(x):\n",
    "    return 1/(1+math.exp(-x))\n",
    "\n",
    "#testing\n",
    "\n",
    "sigmoid_test=sigmoid(4)\n",
    "print(sigmoid_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ReLU Activation Function**\n",
    "\n",
    "If the input value is greater than or equal to zero, the output is equal to the input value.\n",
    "\n",
    "If the input value is negative, the output is zero"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\text{ReLU}(x) = \\max(0, x)\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "def Relu(x):\n",
    "    return x if x>0 else 0\n",
    "\n",
    "#testing\n",
    "\n",
    "relu_test=Relu(-4)\n",
    "print(relu_test)\n",
    "\n",
    "relu_test=Relu(4)\n",
    "print(relu_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**tanh Activation Function**\n",
    "\n",
    "The tanh activation function, also known as the hyperbolic tangent function, is a non-linear function that maps input values between -1 and 1. It is used in neural networks to convert linear inputs and models into non-linear output signals. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\tanh(x) = \\frac{e^{x} - e^{-x}}{e^{x} + e^{-x}}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.7615941559557649\n"
     ]
    }
   ],
   "source": [
    "def tanh(x):\n",
    "    return (math.exp(x)-math.exp(-x))/(math.exp(x)+math.exp(-x))\n",
    "\n",
    "#testing\n",
    "\n",
    "tanh_test=tanh(-1)\n",
    "print(tanh_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Softmax Activation function**\n",
    "\n",
    "The softmax activation function transforms the raw outputs of the neural network into a vector of probabilities, essentially a probability distribution over the input classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\text{softmax}(x)_i = \\frac{e^{x_i}}{\\sum_{j=1}^{n} e^{x_j}} \\quad \\text{for } i = 1, \\ldots, n\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9525329328226693, 4.324492824660289e-05, 0.04742382224908419]\n"
     ]
    }
   ],
   "source": [
    "def Softmax(x):\n",
    "    # x--> list\n",
    "    exp_x=[math.exp(i) for i in x]\n",
    "    sum_exp_x=sum(exp_x)\n",
    "    # compute softmax for each element in x\n",
    "    return [j/sum_exp_x for j in exp_x]\n",
    "\n",
    "#testing\n",
    "\n",
    "Softmax_test=Softmax([9,-1,6])\n",
    "print(Softmax_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow-test",
   "language": "python",
   "name": "tensorflow-test"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
