{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries for data manipulation, visualization, and machine learning\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import PIL\n",
    "import tensorflow as tf\n",
    "\n",
    "# Import specific components from TensorFlow and Keras\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "# Define the URL for the dataset and download it using TensorFlow's utility function\n",
    "dataset_url = \"https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz\"\n",
    "data_dir = tf.keras.utils.get_file('flower_photos', origin=dataset_url, cache_dir='.', untar=True)\n",
    "\n",
    "# Convert the data directory path to a pathlib object\n",
    "# Pathlib is a native Python library for handling files and paths on your operating system.\n",
    "import pathlib\n",
    "data_dir = pathlib.Path(data_dir)\n",
    "data_dir\n",
    "\n",
    "# You can use pathlib object \"data_dir\" to do operation like give me all the images with .jpg extension.\n",
    "# Getting images with .jpg extension.\n",
    "list(data_dir.glob(\"*/*.jpg\"))\n",
    "\n",
    "# Total number of images we have\n",
    "image_count = len(list(data_dir.glob(\"*/*.jpg\")))\n",
    "image_count\n",
    "\n",
    "# glob is useful to get path of images with particular label\n",
    "roses = list(data_dir.glob(\"roses/*\"))\n",
    "roses[:5]\n",
    "\n",
    "# PIL stands for Python Imaging Library, and it's the original library that enabled Python to deal with images.\n",
    "# Using PIL show roses\n",
    "PIL.Image.open(str(roses[0]))\n",
    "\n",
    "# Using PIL show tulips\n",
    "tulips = list(data_dir.glob(\"tulips/*\"))\n",
    "PIL.Image.open(str(tulips[0]))\n",
    "\n",
    "# Create dictionaries to store images and their corresponding labels\n",
    "flowers_images_dict = {\n",
    "    'roses': list(data_dir.glob('roses/*')),\n",
    "    'daisy': list(data_dir.glob('daisy/*')),\n",
    "    'dandelion': list(data_dir.glob('dandelion/*')),\n",
    "    'sunflowers': list(data_dir.glob('sunflowers/*')),\n",
    "    'tulips': list(data_dir.glob('tulips/*')),\n",
    "}\n",
    "\n",
    "# Accessing the particular flower from flowers_images_dict\n",
    "flowers_images_dict[\"roses\"]\n",
    "\n",
    "# Assign numerical labels to each category of flowers\n",
    "flowers_labels_dict = {\n",
    "    'roses': 0,\n",
    "    'daisy': 1,\n",
    "    'dandelion': 2,\n",
    "    'sunflowers': 3,\n",
    "    'tulips': 4,\n",
    "}\n",
    "\n",
    "# Getting the path of particular image\n",
    "flowers_images_dict[\"roses\"][0]\n",
    "\n",
    "# Now we can use cv2 module to read any image file in OpenCV object (like numpy array)\n",
    "# OpenCV expects string path so default one doesn't work\n",
    "# So we need to wrap up in str to give it to OpenCV\n",
    "img = cv2.imread(str(flowers_images_dict[\"roses\"][0]))\n",
    "img\n",
    "\n",
    "# Above OpenCV read the image from disk & convert to 3D numpy array.\n",
    "# Viewing 3D numpy array\n",
    "img.shape\n",
    "\n",
    "# In the data, we have images with different dimensions and to train the model we need all the images in same dimensions. OpenCV helps with that.\n",
    "# OpenCV resize the image\n",
    "cv2.resize(img, (180, 180)).shape\n",
    "\n",
    "# Getting the keys and values from our dictionary\n",
    "for flowers_name, images in flowers_images_dict.items():\n",
    "    print(flowers_name)\n",
    "    print(len(images))\n",
    "\n",
    "# Preparing the X and Y while resizing the images\n",
    "x, y = [], []\n",
    "\n",
    "for flowers_name, images in flowers_images_dict.items():\n",
    "    for image in images:\n",
    "        img = cv2.imread(str(image))\n",
    "        resized_img = cv2.resize(img, (180, 180))\n",
    "        x.append(resized_img)\n",
    "        y.append(flowers_labels_dict[flowers_name])\n",
    "\n",
    "\"\"\"\n",
    "You can call flowers_labels_dict because of\n",
    "Shared Keys: Both flowers_images_dict and flowers_labels_dict use the same keys\n",
    "(flower category names like 'roses', 'daisy', etc.).\n",
    "\"\"\"\n",
    "\n",
    "# For further operations we need X and Y in NumPy arrays so we do conversion to NumPy arrays\n",
    "x = np.array(x)\n",
    "y = np.array(y)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=0)\n",
    "x_test[0]\n",
    "\n",
    "# Image data is not scaled so we need to scale it by dividing by 255\n",
    "# Scaling\n",
    "x_train_scaled = x_train / 255\n",
    "x_test_scaled = x_test / 255\n",
    "\n",
    "# Viewing the scaled value\n",
    "x_train_scaled[0]\n",
    "\n",
    "# Define the convolutional neural network (CNN) architecture using Keras Sequential API\n",
    "# Number of classes (flowers that we have 5)\n",
    "num_classes = 5\n",
    "\n",
    "model = Sequential([\n",
    "    # Making convolutional layer\n",
    "    layers.Conv2D(16, 3, padding=\"same\", activation=\"relu\"),\n",
    "    layers.MaxPooling2D(),\n",
    "    layers.Conv2D(32, 3, padding=\"same\", activation=\"relu\"),\n",
    "    layers.MaxPooling2D(),\n",
    "    layers.Conv2D(64, 3, padding=\"same\", activation=\"relu\"),\n",
    "    layers.MaxPooling2D(),\n",
    "\n",
    "    # To pass CNN to Dense layer we need to convert it into 1D using Flatten layer\n",
    "    layers.Flatten(),\n",
    "    # Making Dense layer\n",
    "    layers.Dense(128, activation=\"relu\"),\n",
    "    layers.Dense(num_classes)\n",
    "])\n",
    "\n",
    "model.compile(optimizer=\"adam\",\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "model.fit(x_train_scaled, y_train, epochs=30)\n",
    "\n",
    "\"\"\"\n",
    "Setting from_logits=True means that the model's output isn't transformed\n",
    "(like using softmax) before calculating the loss. Instead, it directly uses\n",
    "the raw predictions from the model. This can be better for numerical stability\n",
    "and efficiency during training.\n",
    "\"\"\"\n",
    "\n",
    "model.evaluate(x_test_scaled, y_test)\n",
    "\n",
    "# Doing prediction using our model\n",
    "predictions = model.predict(x_test_scaled)\n",
    "predictions\n",
    "\n",
    "# Above we are getting very scattered output because when we build a Dense network we didn't specify the output layer. So the default activation function is linear activation function\n",
    "# Converting the scattered output to probability score\n",
    "score = tf.nn.softmax(predictions[1])\n",
    "score\n",
    "np.argmax(score)\n",
    "\n",
    "# It predicted the second image as rose\n",
    "\n",
    "# We can verify from y_test that it predicted correctly\n",
    "y_test[1]\n",
    "\n",
    "# Still, our model gives only 50% accuracy so we can fix that by using data augmentation\n",
    "data_augmentation = keras.Sequential([\n",
    "    layers.experimental.preprocessing.RandomZoom(0.9),\n",
    "])\n",
    "\n",
    "# Original Image\n",
    "plt.axis('off')\n",
    "plt.imshow(x[0])\n",
    "\n",
    "# Newly generated training sample using data augmentation\n",
    "plt.axis('off')\n",
    "plt.imshow(data_augmentation(x)[0].numpy().astype(\"uint8\"))\n",
    "\n",
    "# From above image you can see that RandomZoom makes the image zoomed out\n",
    "\n",
    "# There are different data augmentations like contrast, rotate, etc.\n",
    "data_augmentation = keras.Sequential([\n",
    "    layers.experimental.preprocessing.RandomZoom(0.3),\n",
    "])\n",
    "\n",
    "# Applying data augmentation to our data\n",
    "# Define image augmentation preprocessing layers using Keras Sequential API\n",
    "img_height = 180\n",
    "img_width = 180\n",
    "data_augmentation = keras.Sequential([\n",
    "    layers.experimental.preprocessing.RandomFlip(\"horizontal\", input_shape=(img_height, img_width, 3)),\n",
    "    layers.experimental.preprocessing.RandomRotation(0.1),\n",
    "    layers.experimental.preprocessing.RandomZoom(0.1)\n",
    "])\n",
    "\n",
    "# Train the model using data augmentation and a dropout layer\n",
    "num_classes = 5\n",
    "\n",
    "model = Sequential([\n",
    "    data_augmentation,\n",
    "    layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
    "    layers.MaxPooling2D(),\n",
    "    layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
    "    layers.MaxPooling2D(),\n",
    "    layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
    "    layers.MaxPooling2D(),\n",
    "    layers.Dropout(0.2),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(num_classes)\n",
    "])\n",
    "\n",
    "# Compile the model with appropriate loss function, optimizer, and evaluation metric\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model on the training data with data augmentation for 30 epochs\n",
    "model.fit(x_train_scaled, y_train, epochs=30)\n",
    "\n",
    "# Evaluating the model on test data\n",
    "model.evaluate(x_test_scaled, y_test)\n",
    "\n",
    "# So by doing data augmentation we got standard results here\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
